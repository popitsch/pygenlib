{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0580641a-d103-4972-b263-9fcc21959431",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115b498-61b8-41fb-9a0f-546cb3bebbf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "The increasing abundance and complexity of biological data often requires programatic approaches for their analysis that allow for the rapid development of custom yet efficient, well-tested and reproducible analysis pipelines. \n",
    "\n",
    "Traditional approaches (e.g., bash command/perl pipelines), that suffer from low readability, maintainability and reproducibility,\n",
    "are increasingly superseded by complex, containerized (e.g., Singularity) analysis pipelines that combine specialized bioinformatics tools \n",
    "with custom scripts developed in higher programming languages such as *Python*, *R* or *Rust*.\n",
    "\n",
    "Despite not being the fastest option, *Python* is a [popular choice by analysts](https://github.blog/2023-03-02-why-python-keeps-growing-explained/), mainly due to the large number of available (bioinformatics) libraries, its simple and well-documented syntax and its broad utility in the emerging data science field.\n",
    "\n",
    "For this reason an increasing number of python APIs for the handling of genomics data are being developed. \n",
    "While some are mainly wrappers around well-established bioinformatics tools (e.g., pysam/samtools, pybedtools/BEDTools or cyvcf2/htslib) others are builing on efficient data wrangling/analysis libraries such as *pandas* or *numpy* (e.g., bioframe/pandas, pyranges/pandas, bionumpy/numpy).\n",
    "\n",
    "Here, we present *rnalib*, a python utilities library for handling genomics data with a focus on transcriptomics and \n",
    "\n",
    "In a [second notebook](RelatedWork_performance.ipynb), we compare rnalib to a number of related APIs with regard to provided features and performance. We additionally demonstrate some common analysis pitfalls that we tried to address in the design of our library.\n",
    "\n",
    "We provide a set of tutorials for demonstrating rnalib in realistic usage scenarios:\n",
    "* [Tutorial: Read mismatch analysis](Tutorial_mismatch_analysis.ipynb)\n",
    "* [Tutorial: Comparison of gene annotation sets](Tutorial_compare_annotation_sets.ipynb)\n",
    "* [Tutorial: shRNA analysis](Tutorial_shRNA_analysis.ipynb)\n",
    "* [Tutorial: Transcriptome analysis](Tutorial_transcriptome_annotation.ipynb)\n",
    "\n",
    "Finally, we showcase how the combination of (the strengths of) multiple genomics libraries leads to an overall benefit in multiple tutorials:\n",
    "* [Tutorial: CTCF analysis with rnalib and bioframe](Tutorial_CTCF_analysis.ipynb)\n",
    "* [Tutorial: Expression analysis with rnalib and genemunge](Tutorial_expression_analysis.ipynb)\n",
    "\n",
    "\n",
    "## Test datasets\n",
    "\n",
    "This notebook as well as rnalib's testing suite use various test data files that can be created by running the rnalib testdata python script. This class contains a `test_resources` dict that describes the various test resources and their origin. Once downloaded, test data resources can be accessed via `get_resource(<resource_id>)`.\n",
    "\n",
    "The tutorial notebooks contain respective cells for (temporarily) downloading larger test files that are needed to demonstrate rnalib under realistic conditions. \n",
    "\n",
    "Note that rnalib expects all referenced genomics datasets to be compressed and indexed (e.g., BED files must be bgzipped and accompanied by a tabix index; SAM files must be in binary (BAM) format and accompanied by a BAM (bai) index). This ensures that these datasets are coordinate-sorted and can be efficiently sliced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474387e-b7f8-4207-8154-d496a4938240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set path and load rnalib\n",
    "import os, pathlib, platform\n",
    "rnalib_SRC=pathlib.Path('/Users/niko/projects/rnalib/') \n",
    "os.chdir(rnalib_SRC)\n",
    "# install libraries. Recommended to run in a venv here!\n",
    "#!{sys.executable} -m pip install -r requirements.txt \n",
    "display(f\"Running rnalib on python {platform.python_version()}. Using rnalib code from {rnalib_SRC}\")\n",
    "# load rnalib\n",
    "import rnalib as pg\n",
    "from rnalib import gi, SEP, display_textarea\n",
    "# load other libs\n",
    "import biotite.sequence as seq\n",
    "from Bio.Align import PairwiseAligner\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pybedtools \n",
    "import bioframe\n",
    "import tempfile\n",
    "import pytest\n",
    "import dataclasses\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ac0fc-b7f0-4113-99a2-7fd395cd101c",
   "metadata": {},
   "source": [
    "# rnalib\n",
    "\n",
    "rnalib is a python utilities library for handling genomics data with a focus on transcriptomics. \n",
    "It is roughly structured into the following modules:\n",
    "\n",
    "- [iterators](#Iterators): efficient iteration over subregions of large-scaled genomics datasets based on the pysam library. Iterators keep track of the genomic region of the\n",
    "  yielded data enabling their efficient integration with other genomics data\n",
    "- [transcriptome](#Transcriptome): python classes for modeling gene/transcript annotations and many useful querying/annotation methods.\n",
    "- [utils](#Utility-functions): general (low-level) utility functions for working with genomics datasets.\n",
    "\n",
    "\n",
    "rnalib implements a transcriptome data model that preserved parent/child relationships between features (e.g., transcripts and introns) and a secure way for annotating such features by structuring them into immutable genomic locations (that can, e.g., safely be used in lookup tables) and mutatble, arbitrary annotations. \n",
    "\n",
    "\n",
    "Transcriptomics analyses require the integration of various biological data sources (e.g., gene/transcript annotations, sequence alignment data, genomic scores, etc.) which is why rnalib implement variour genomic iterators on top of existing python implementations (pysam, bioframe, pybedtools).\n",
    "\n",
    "This ipython notebook demonstrates some of rnalib's functionality and API using simple and complex access examples. Please also refer to rnalib's test classes for further API examples.\n",
    "\n",
    "Note that this notebook uses various genomics data test files that can be accessed via the `rnalib.testdata.get_resource('<test_resource_id'>` method. See the testdata.py class for details how these files were created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ecb24-235c-48f4-aadf-7d13776b5c69",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genomic intervals\n",
    "At the heart of rnalib is its representation of genomic regions (intervals), represented by the  *genomic intervals* (gi) class in rnalib:\n",
    "- Genomic intervals (gi) in rnalib are inclusive and 1-based.\n",
    "  - This model was chosen to make interpretation of GIs straightforward: the start and end coordinates represent the first/last included nucleotide as also seen in a genome browser (such as IGV)\n",
    "- GIs are implemented as frozen (pseudo immutable) dataclasses \n",
    "  - GIs can theredore be safely used as keys in a dict.\n",
    "- GIs can be instantiated by passing chrom/start/stop coordinates or can be parsed form a string.\n",
    "- GIs can be stranded. Unstranded intervals are represented by setting strand to None (default) \n",
    "- Using None for each component of the coordinates is allowed to represent unbounded intervals. Examples:\n",
    "  - gi('chr1') refers to the whole chromosome\n",
    "  - gi('chr1', 100000) refers to the section of chromosome 1 from (and including) positon 100k on.\n",
    "  - gi(start=100, end=200) refers to positions 100-200 (inclusive) on any chromosome \n",
    "- Points are represented by GIs with same start and end coordinate.\n",
    "  - Thus are intervals that represent exactly one nucleotide.\n",
    "- Empty intervals are represented by GIs with start>end coordinates (experimental).\n",
    "  - Several real genomics datasets contain (wrongly annotated) empty intervals that can easily be filtered bz rnalib.\n",
    "\n",
    "GIs represent genomic intervals on a chromosome of some reference genome. Chromosome order in such a genome is represented by *ReferenceDict*s (which extend regular python dicts).\n",
    "- ReferenceDicts can be used to properly sort genomic intervals (see example below)\n",
    "- ReferenceDicts keep track of the available chromosomes and their length and are typically directly derived from genomic data (index) files\n",
    "- ReferenceDicts are used in rnalib to check for compatibility of different genomic datasets\n",
    "\n",
    "\n",
    "More documentation can be accessed via\n",
    "`help(gi)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd3d62-7b49-473f-9749-1a567872260c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list of genomic intervals\n",
    "locs=[gi('chr2', 1, 100), # chr2:1-100, unstranded\n",
    "      gi.from_str('chr1:5-500 (+)'),  # parsed from string, strand='+'\n",
    "      gi.from_str('chr3:50-120 (-)'), \n",
    "      gi.from_str('chr1:10-20 (-)'), \n",
    "      gi(None, None, 1000, '-'), # chromosome and start unbound, end=1000, strand='-'\n",
    "      gi(None, 10, 1000, '-')] # chromosome unbound\n",
    "display('Sorted by start coordinate but order of chromosomes is undefined:', sorted(locs), SEP)\n",
    "\n",
    "# To sort also by chromosome, you can use a reference dict which defined the chromosome order:\n",
    "refdict=pg.ReferenceDict({'chr1':None, 'chr2':None, 'chr3':None}, 'test', None)\n",
    "display(refdict, SEP)\n",
    "# And then call the gi.sort(...) method which is basically returning \n",
    "# sorted(locs, key=lambda x: (refdict.index(x.chromosome), x))\n",
    "display('Properly sorted list:', gi.sort(locs, refdict))\n",
    "# Note that typically you don't need to do this as rnalib deals with bgzipped+tabixed files that are always \n",
    "# sorted and automatically derived reference dicts from the index. For manually created intervals or interval \n",
    "# sets derived via other sources that allow access to (potentially) unsorted files (e.g., rnalib), you can \n",
    "# use gi.sort() \n",
    "\n",
    "# Unbounded intervals (chromosome=None) will always be at the beginning of the list. \n",
    "# Generally, the order of intervals from different groups (chromosomes) is left undefined.\n",
    "display(f\"Is the greater-than comparison chr2:1-1>chr1:1-1 defined? {gi('chr2', 1, 1) > gi('chr1', 1, 1)}\", SEP)\n",
    "\n",
    "# All intervals with start>end coordinate is considered 'empty'; internally, its coordinates are set to [0, maxint].\n",
    "empty_interval=gi('1',2,1)\n",
    "\n",
    "# Empty intervals have zero length\n",
    "display(f\"The length of empty interval is {len(empty_interval)}, the length of unbounded intervals is defined as 2^31-1 (assuming int32): {len(empty_interval)}\", SEP)\n",
    "display(f\"Empty intervals do not overlap/do not envelop any interval including itself (overlap={empty_interval.overlaps(empty_interval)})\")\n",
    "display(f\"Empty intervals are considered equal to any other empty interval on the same chromosome: ({empty_interval==gi('1',20,19)})...\")\n",
    "display(f\"...but different from empty intervals on other chromosomes to not break chromsome order ({empty_interval==gi('2',20,19)})\", SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0f52e-1c1f-44c3-af27-e2c2d504718f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19601ee3-c724-430e-bec9-411e9e496c85",
   "metadata": {
    "tags": []
   },
   "source": [
    "_rnalib_ implements several *LocationIterator*s for efficient iteration over (parts of) genomics datasets while keeping track of the [genomic interval](#Genomic-intervals) each yielded item refers to. Most implemented iterators are based on respective [pysam](https://pysam.readthedocs.io/en/latest/api.html) classes but extend them with different filtering/access methods and add sanity checks to avoid common errors when combining different genomics datasets.\n",
    "The primary goal of LocationIterators is to support the synchronization/integration of different genomics datasets. LocationIterators also support chunked I/O where feasible and not supported by the underlying (pysam) implementation.\n",
    "\n",
    "LocationIterators can iterate whole datasets or specific sub-region (e.g., a certain chromosome or genomic region). Yielded data items are sorted by respective [genomic intervals](#Genomic-intervals) where the order of chromosomes is defined by a [ReferenceDict](#Genomic-intervals) that is derived directly from the iterated dataset (e.g., by querying it's tabix index). When multiple LocationIterators are integrated (e.g., by an AnnotationIterator), their ReferenceDicts are checked for compatibility.\n",
    "\n",
    "Sometimes, genomics datasets from different providers used differing chromosome ids to refer to the same chromosomes which hinders their integration. \n",
    "Location iterators support chromosome aliasing as a quick solution for this: users can provide aliasing functions (e.g., for adding/removing 'chr' prefixes from \n",
    "chromosome ids) to dynamically change chromosome ids while keeping the underlying data files untouched.\n",
    "\n",
    "Implemented LocationIterators include:\n",
    "* [MemoryIterator](#MemoryIterator): iterates over genomic interval sets stored in various default python data structures (list, dicts).\n",
    "* [FastaIterator](#FastaIterator): iterates FASTA files per position or genomic window (e.g., Tiling/sliding windows).\n",
    "* [FastqIterator](#FastqIterator): iterates FASTQ entries (NOTE that this is no LocationIterator)\n",
    "* [GFF3Iterator](#GFF3Iterator): iterates GTF/GFF3 files and parses annotation data. Used for the [Transcriptome](#transcriptome) implementation\n",
    "* [ReadIterator](#ReadIterator): iterates SAM/BAM files and implements various filter options. \n",
    "* [FastPileupIterator](#FastPileupIterator): a faster alternative to pysam's pileup method\n",
    "* [VcfIterator](#AnnotationIterator): iterates VCF files and can filter for samples\n",
    "* [AnnotationIterator](#AnnotationIterator): annotates the items from one LocationIterator with items from others\n",
    "\n",
    "and many more (see API documentation).\n",
    "The following sections showcase some of the implemented iterators:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc22c5-02ca-4b17-8fa0-90aa1c19d69b",
   "metadata": {},
   "source": [
    "### MemoryIterator\n",
    "Iterates over genomic interval sets stored in various default python data structures (list, dicts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d8bbf-5adc-49a3-8659-916c55cbac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we iterate over a list. Intervals will be sorted and the index (int the original input list) will be reported in the data section.\n",
    "display(pg.MemoryIterator([gi.from_str('chr1:100-1000'), \n",
    "                        gi.from_str('chr1:100-1000'), # duplicate interval that will be reported\n",
    "                        gi.from_str('chr1:10-100'), \n",
    "                        gi.from_str('chr2:12-64')]).to_list(), SEP )\n",
    "# Here we iterate over a dict. The mapped values will be reported in the data section.\n",
    "display(pg.MemoryIterator({gi.from_str('chr1:100-1000'): 'a1', \n",
    "                        gi.from_str('chr1:100-1000'): 'a2', # This will replace 'a1' in the dict!\n",
    "                        gi.from_str('chr1:10-100'): 'b', \n",
    "                        gi.from_str('chr2:12-64'): 'c'}).to_list(), SEP )\n",
    "# Here we iterate over a reverse dict. This allows for iterating duplicate intervals with different IDs.\n",
    "display(pg.MemoryIterator({'a1': gi.from_str('chr1:100-1000'), \n",
    "                        'a2': gi.from_str('chr1:100-1000'),\n",
    "                        'b':  gi.from_str('chr1:10-100'), \n",
    "                        'c':  gi.from_str('chr2:12-64')}).to_list() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262da942-1ef3-45da-ad9a-3da72463ad8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FastaIterator\n",
    "Iterates over a FASTA file but enables also tiling/sliding windows and padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64ed77-f33f-4360-89c2-b80470284243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get 5mer sliding windows (step size 2) with padding from a GRCh38 chr7 region around ACTB; \n",
    "# show first and last 5 results.\n",
    "# item.data returns the data item returned by this iterator (here: a string containing the kmer)\n",
    "# item.location (not used in this example) is a GI describing the genomic location of this sequence\n",
    "with pg.FastaIterator(pg.get_resource('ACTB+SOX2_genome'), # a sliced version of the reference genome.\n",
    "                      region=gi('chr7', 0, 1000), # iterated region\n",
    "                      width=5, # report 5-mers\n",
    "                      step=2,  # step size: 2\n",
    "                      padding=True) as it:\n",
    "    kmers = [kmer for loc,kmer in it] # take consumes all items from the iterator\n",
    "display(f\"{kmers[:5]}...{kmers[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1b71d-897f-4b2a-a2b5-0aa61eca7243",
   "metadata": {},
   "source": [
    "### FastqIterator\n",
    "Iterates over a FASTQ file and returns named tuples (name seq qual) containing read names, sequence \n",
    "and quality strings. Note that this is no Location iterator as unaligned reads have no (known) genomic location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924ba95-275d-415a-8f4c-91ac318ca8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate over PE reads in two FASTQ files and display their read names and sequence lengths.\n",
    "# We use pythons zip() method to access tuples of reads\n",
    "for r1,r2 in zip(pg.FastqIterator(pg.get_resource('small_PE_fastq1')), \n",
    "                 pg.FastqIterator(pg.get_resource('small_PE_fastq2'))):\n",
    "    display(f\"{r1.name}, {r2.name}\")\n",
    "    display(f\"len r1: {len(r1.seq)}, len r2: {len(r2.seq)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404c692-c861-4919-8413-c781ac347856",
   "metadata": {},
   "source": [
    "### VCFIterator\n",
    "Iterates over VCF files and yields VcfRecords that wrap (and partially parse) pysam VcfProxy objects.\n",
    "It provides convenience methods to access and filter contained samples and enables filtering based on called \n",
    "genotype, number of calls across samples or zygosity. Additional format columns are automatically parsed and accessible via dot-notation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4d258-7327-44f0-9a6c-0cb2dac074e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=Counter()\n",
    "with pg.VcfIterator(pg.get_resource('dmel_multisample_vcf')) as it:\n",
    "    # show included samples\n",
    "    display(f'Contained samples: {len(it.allsamples)}, e.g., {it.allsamples[:3]}')\n",
    "    for loc,vr in it:\n",
    "        # include only variants that are called (i.e., not './.') in more than half of the samples\n",
    "        if vr.n_calls/len(vr.GT)>0.5:\n",
    "            stats[f\"{vr.ref}/{vr.alt}\"] += 1\n",
    "display('all variants:', stats, SEP)\n",
    "\n",
    "# repeat analysis , this time considering 3 samples only\n",
    "stats=Counter()\n",
    "with pg.VcfIterator(pg.get_resource('dmel_multisample_vcf'), \n",
    "                    samples=['DGRP-738', 'DGRP-859', 'DGRP-59']) as it:\n",
    "    for loc,vr in it: # this will skip all entries that are uncalled in the 3 samples\n",
    "        stats[f\"{vr.ref}/{vr.alt}\"] += 1\n",
    "display('3 sample variants:', stats, SEP)\n",
    "\n",
    "# show access to ID column, INFO dict and FORMAT data (per sample!)\n",
    "with pg.VcfIterator(pg.get_resource('test_vcf')) as it:\n",
    "    for loc,vr in it: \n",
    "        display(f\"{vr}, ID: {vr.id}, END: {vr.info.get('END', 'NA')}, CS: {vr.CS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2536d-19fe-4f87-80f8-949b2163441e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GFF3Iterator\n",
    "Iterates over GFF3 files and yields dicts containing parsed annotation fields. This iterator\n",
    "is used for building transcriptome features as discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18afb5-5874-46a4-9fdd-80ac25276c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show first two data items from a GFF3 file\n",
    "pg.display_list(pg.GFF3Iterator(pg.get_resource('gencode_gff')).to_list()[:2])\n",
    "\n",
    "# iterate whole GFF3 file and collect stats of contained feature_type annotations\n",
    "display(Counter([item.data['feature_type'] for item in pg.GFF3Iterator(pg.get_resource('gencode_gff'))]))\n",
    "\n",
    "# iterate transcripts and collect stats of contained transcript_type annotations\n",
    "display(Counter([item.data.get('transcript_type', 'NA') for item in \\\n",
    "                 pg.GFF3Iterator(pg.get_resource('gencode_gff')) if item.data['feature_type']=='transcript']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987a903-200a-4ae4-b536-0c4671bb1757",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ReadIterator\n",
    "Iterates SAM/BAM files and implements several filter options. Also keeps track of how many reads were filtered for what reason.\n",
    "Can also yield mismatches wrt. the reference if MD tags are available (can be added, e.g., by [samtools calmd](http://www.htslib.org/doc/samtools-calmd.html) if not added by the mapper itself). See the respective tutorial \n",
    "for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6f14e-cf57-4f9e-b100-4ed82a0f9944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count reads per chromosome in a BAM using different filters\n",
    "stats={x:Counter() for x in ['all', 'def', 'mq20', 'tag']}\n",
    "with pg.open_file_obj(pg.get_resource('small_example_bam')) as bam:\n",
    "    for chrom in tqdm(pg.ReferenceDict.load(bam)):\n",
    "        with pg.ReadIterator(bam, chrom, flag_filter=0) as it: # all: no filtering\n",
    "            it.to_list()\n",
    "            stats['all'].update(it.stats)\n",
    "        with pg.ReadIterator(bam, chrom) as it: # def: default flag filter (as in IGV)\n",
    "            it.to_list()\n",
    "            stats['def'].update(it.stats)\n",
    "        with pg.ReadIterator(bam, chrom, min_mapping_quality=20) as it: # mq20: default flag filter, mapping quality >= 20\n",
    "            it.to_list()\n",
    "            stats['mq20'].update(it.stats)\n",
    "        with pg.ReadIterator(bam, chrom, tag_filters=[pg.TagFilter('MD', ['100'])]) as it: # tag: default flag filter, MD tag must be '100'\n",
    "            it.to_list()\n",
    "            stats['tag'].update(it.stats)\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf7876-3d0f-475b-a5bf-2ea3bea35a09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FastPileupIterator\n",
    "rnalib contains a `FastPileupIterator` for fast and lightweight pileup-style access to alignment columns (i.e., all reads at a particular genomic position).\n",
    "Here we compare it to [pysam](https://pysam.readthedocs.io/en/latest/)'s pileup method (which adds a lot of boilerplate + additional checks) and reach a ~10-20X performance increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9135a-9d2a-4a74-b37b-b97546641e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg=gi('1',22377202,22429853) # the iterated region\n",
    "times=defaultdict(Counter) \n",
    "# Counter for storing the results. Will contain one GI entry per position which is itself an {allele:count} Counter.\n",
    "with pg.Timer(times, 'FastPileupIterator') as timer:\n",
    "    ac1=Counter()\n",
    "    with pg.open_file_obj(pg.get_resource('small_example_bam')) as bam:\n",
    "        for l,v in tqdm(pg.FastPileupIterator(bam, reg.chromosome, range(reg.start, reg.end))):\n",
    "            ac1[l.chromosome, l.start]=v\n",
    "with pg.Timer(times, 'PysamPileup') as timer:\n",
    "    ac2=Counter()\n",
    "    with pg.open_file_obj(pg.get_resource('small_example_bam')) as bam:\n",
    "        for pu in tqdm(bam.pileup(contig=reg.chromosome, start=reg.start-1, stop=reg.end-1, \n",
    "                                  flag_filter=pg.DEFAULT_FLAG_FILTER, truncate=True, mark_ends=True,\n",
    "                                  add_indels=True, min_base_quality=0, min_mapping_quality=0,\n",
    "                                  ignore_overlaps=False, ignore_orphans=False, max_depth=100000)):\n",
    "            pos=(pu.reference_name, pu.reference_pos+1)\n",
    "            ac2[pos]=Counter()\n",
    "            for r in pu.pileups:\n",
    "                if r.is_refskip:\n",
    "                    continue\n",
    "                elif r.is_del:\n",
    "                    ac2[pos][None]+=1\n",
    "                else:\n",
    "                    ac2[pos][r.alignment.query_sequence[r.query_position]]+=1\n",
    "\n",
    "# PysamPileup will not iterate/report uncovered alignment columns. So, here we add empty Counters for those positions\n",
    "for p in (ac1.keys() - ac2.keys()):\n",
    "    ac2[p]=Counter()\n",
    "          \n",
    "# now compare the resulting counters\n",
    "assert ac1==ac2\n",
    "\n",
    "# plot the times\n",
    "pg.plot_times('Pileup performance', times, n=len(reg), reference_method='FastPileupIterator')\n",
    "\n",
    "# show some example columns\n",
    "pg.head_counter(ac1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801946b-3d04-473d-a0d9-03f547557fe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AnnotationIterator\n",
    "\n",
    "Data integration is a central use case for genomic libraries which often requires the annotation of genomic intervals with data derived from other, overlapping genomic intervals. One example is to calculate a score baed on data associated with all overlapping intervals from one or multiple other dataset(s).\n",
    "\n",
    "There are many different approaches to achieve these tasks:\n",
    "- in [pybedtools](https://daler.github.io/pybedtools), which is based on BEDTools, you could:\n",
    "    - [intersect](https://daler.github.io/pybedtools/autodocs/pybedtools.bedtool.BedTool.intersect.html#pybedtools.bedtool.BedTool.intersect) the respective interval sets\n",
    "    - apply a custom annotation method via [map()](https://daler.github.io/pybedtools/autodocs/pybedtools.bedtool.BedTool.map.html#pybedtools.bedtool.BedTool.map) or [each()](https://daler.github.io/pybedtools/autodocs/pybedtools.bedtool.BedTool.each.html#pybedtools.bedtool.BedTool.each) method\n",
    "- In [bioframe](https://bioframe.readthedocs.io/), which is based on pandas dataframes, you could:\n",
    "    - first use [overlap()](https://bioframe.readthedocs.io/en/latest/guide-intervalops.html#overlap) to intersect the interval sets\n",
    "    - then group on the annotated feature location using pandas [groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) method\n",
    "    - and finally apply some [user defined mutate methods](https://pandas.pydata.org/docs/user_guide/gotchas.html#gotchas-udf-mutation) via apply() or aggregate().\n",
    "\n",
    "`rnalib` contains an `AnnotationIterator` for annotating genomic intervals with data from one or *multiple* other genomic location iterators.\n",
    "This iterator synchronizes genomic locations of the primary iterator (iterating the intervals to be annotated) with all annotating iterators and yields respective locations and data for all overlapping intervals. In the example below, we iterate over annotations in a genomic subregion of a flybase GTF file and annotate all features with  (i) a list of SNPs that were called in 3 particular samples of a multi-sample VCF file and (ii) values from bedgraph file.\n",
    "\n",
    "**Note** that iterating over large interval sets is generally considered slow and is often not needed. \n",
    "In many cases you can use list [comprehension, vectorisation](https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-pandas-dataframe/)\n",
    "or mechanisms such as [pandas apply()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) or [pybedtools each()](https://daler.github.io/pybedtools/each.html) as described above. \n",
    "Nevertheless, there are scenarios in which we consider AnnotationIterators  useful, e.g., if you need to access to contextual data (e.g., annotation results from previous data rows) or if you need (fine-grained) access to multiple synchronized datasets in parallel. Performance drawbacks of iteration approaches are also diminished when integrating multiple iterators in parallel. The overall goal of AnnotationIterators is to improve code readability and reduce potential error sources such as [the ones discussed in the 'RelatedWork' notebook](RelatedWork_performance.ipynb#Potential-pifalls). AnnotationIterators are also used by rnalib's [`transcriptome.annotate()`](#Annotation-of-features) method for incremental transcriptome annotation as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79113d3d-12d6-4b1b-a230-ec9f51598e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Annotate flybase GTF annotation with (i) a list of the genotypes of overlapping SNPs for \n",
    "# 3 samples and (ii) the maximum value from a bedgraph track\n",
    "with pg.AnnotationIterator(\n",
    "    pg.GFF3Iterator(pg.get_resource('flybase_gtf'), '2L', 1, 30000), # iterate over 2L:1-30000 in the flybase GTF\n",
    "    [pg.VcfIterator(pg.get_resource('dmel_multisample_vcf'), # annotate with overlapping SNPs but consider 3 samples only\n",
    "                    samples=['DGRP-208', 'DGRP-325', 'DGRP-721']),\n",
    "     pg.BedGraphIterator(pg.get_resource('dmel_randomvalues'))], # annotate with \n",
    "    disable_progressbar=True) as it:\n",
    "    for loc, (gff_feature, overlapping_snps, rand_values) in it.to_list()[:5]: # here we show just the first 5 features...\n",
    "        # Remember that rnalib iterators return named (location, data) tuples. Here, 'snps' is a list of such \n",
    "        # items and we can access the respective VCFRecord objects via the data field:\n",
    "        overlapping_snps=[x.data for x in overlapping_snps]\n",
    "        # rand_values is a sorted list (by genomic location) of overlapping values from the Bedgraph file.\n",
    "        # We use min/max to get the first/last items from this list and access the value via the \n",
    "        # data field and convert from float (as returned by the bedgraph iterator) to int:        \n",
    "        tp_value, fp_value = int(min(rand_values).data), int(max(rand_values).data) \n",
    "        # now we can display some data\n",
    "        display(f\"{gff_feature['feature_type']}@{loc} {gff_feature.get('transcript_id','NA')} (gene {gff_feature['gene_symbol']})\")\n",
    "        display(f\"SNPs: {overlapping_snps}\")\n",
    "        display(f\"3'-value: {tp_value}, 5'-value: {fp_value}\", SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a23c9-69a3-4449-8968-edab8988e154",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Genomic interval arithmetic\n",
    "Here is another example in which we simply annotate intervals from a BED file with the sum of scores or all overlapping intervals from a bedgraph file.\n",
    "As all rnalib `LocationIterators` yield their current genomic interval in a uniform format, it is straightforward to use interval arithmetic in the annotation method (in this example we calculate the overlap fraction to calculate the actual score contributions of overlapping bedgraph intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c387b-8bde-42fe-9590-ad5c859a9b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Annotate all intervals in a BED file with sum of scores from a bedgraph file; supports bedgraph intervals >1bp: \n",
    "# score contribution is calculated from the interval overlap (this bedgraph file contains, e.g., an interval (1:7-10, 0.3))\n",
    "print('rnalib annotation iterator wrapping a Bed- and a BedGraphiterator')\n",
    "with pg.AnnotationIterator(pg.BedIterator(pg.get_resource('test_bed')), \n",
    "                           pg.BedGraphIterator(pg.get_resource('test_bedgraph')), \n",
    "                           labels=['scores'], disable_progressbar=True) as it:\n",
    "    for loc, i in it:\n",
    "        display(f\"Annotation {i.anno}, sum:{sum([x.data*loc.overlap(x.location) for x in i.scores])}\")\n",
    "    display(it.stats())\n",
    "display(SEP)\n",
    "    \n",
    "    \n",
    "# Same as above, just for demonstration purposes, but now using pybedtools iterators that wrap a pybedtools BedTool\n",
    "print('rnalib annotation iterator wrapping two PybedtoolsIterators')\n",
    "with pg.AnnotationIterator(pg.PybedtoolsIterator(pg.get_resource('test_bed')), \n",
    "                           pg.PybedtoolsIterator(pg.get_resource('test_bedgraph')), \n",
    "                           labels=['scores'], disable_progressbar=True) as it:\n",
    "    for loc, i in it:\n",
    "        # Note the slight differences. The returned data is now a pybedtools item, access to the \n",
    "        # bedgraph score is via the name attribute (but its a string, so we need to convert to float). \n",
    "        display(f\"Annotation {i.anno}, sum:{sum([float(x.data.name)*loc.overlap(x.location) for x in i.scores])}\")\n",
    "    display(it.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017d21e-7c47-4777-b7dd-590e7c2adc67",
   "metadata": {},
   "source": [
    "### TiledIterator for splitting large datasets\n",
    "A common practice of many genomics applications is to break up analyses into continuous blocks (genomic intervals or tiles), e.g., to parallelize computation or just to deal with large datasets. Splitting a reference dict (i.e., a genome representation) into such blocks can easily be done using its `iter_blocks()` method. Iterating over a large BAM file, handling non-overlapping genomic intervals, for example, can be done as shown below.\n",
    "\n",
    "*Note that you could also use an AnnotationIterator for this task as demonstrated above. In this case the region list must be sorted though!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b8136-0e72-43f8-bc9d-487255c4b3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a read iterator and add a 'chr' prefix to the chromosome names (via fun_alias)\n",
    "with pg.ReadIterator(pg.get_resource('small_example_bam'), flag_filter=0, fun_alias=pg.toggle_chr) as it: \n",
    "    # Iterate the alignments and count the number of reads per tile.\n",
    "    with pg.TiledIterator(it, tile_size=int(1e8)) as tit: \n",
    "        # Store the results in a dict, but ony for 'canonical' GRCh38 chromosomes\n",
    "        stats={loc: len(dat) for loc, dat in tit if loc.chromosome in pg.CANONICAL_CHROMOSOMES['GRCh38']}\n",
    "# show first 10 entries of the results dict. There are reads only at the beginning of chromosome 1 in this file.\n",
    "display(dict(list(stats.items())[0:10]), '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72384e7-3495-4cc7-a9b3-d9108b1e63ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here is another example in which we bin data from a begraph file by tiling it into blocks and iterating the respective scores and the locations of the intervals they stem from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568a3de-455b-418c-a7a8-681faa3b40ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show the 'raw' data as a dataframe\n",
    "display(pg.BedGraphIterator(pg.get_resource('test_bedgraph')).to_dataframe())\n",
    "# Create a bedgraph iterator. As we cannot retrieve chromosome lengths from tabix files, \n",
    "# we set `calc_chromlen=True` to estimate them from iterating the file. We can then \n",
    "# calculate tiles that cover all covered regions. \n",
    "with pg.BedGraphIterator(pg.get_resource('test_bedgraph'), calc_chromlen=True) as it:\n",
    "    # Create a list of non-overlapping intervals (tiles) of size 7 from the iterator's refdict.\n",
    "    regions = it.refdict.iter_blocks(block_size=7)\n",
    "    # Iterate the alignments and display the tile interval, the data from the bedgraph file, the respective interval locations and a weighted sum\n",
    "    with pg.TiledIterator(it, regions) as tit:\n",
    "        for loc, dat in tit:\n",
    "            display(f\"{loc}: scores: {dat} locations: {tit.tile_locations}, sum: {sum([x*loc.overlap(y) for x,y in zip(dat, tit.tile_locations)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c8483c-87ee-4af7-8e2e-6aa4cc1f905a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transcriptome implementation\n",
    "_rnalib_ provides a `transcriptome` implementation that enables convenient access/filtering of genomic annotations via python. \n",
    "Briefly, a (filtered) input GTF/GFF file is parsed and respective (frozen) dataclasses that derive from the generic `Feature` class are instantiated. \n",
    "The implementation keeps track of parent/child relationships (e.g., between genes, transcripts and their exons) and enables efficient iteration/querying and annotation of genomic annotations. Data fields and annotations can conveniently be accessed via 'dot' notation (i.e., `<feature>.<attribute>`). \n",
    "\n",
    "Note that the current implementation does not implement the full GFF3 format as specified [here](https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md)\n",
    "but currently rather supports various popular gff 'flavours' as published by encode, ensembl, ucsc, chess, mirgenedb and flybase.\n",
    "It also supports a 'generic' GFF3 format where all parsed features are interpreted as 'transcript' objects irrespecting the actual feature_type column.\n",
    "Respective parent 'gene' annotations are automatically added, no sub-features (exons, introns, etc.) are created.\n",
    "\n",
    "Here is a brief description of the datamodel depicted below:\n",
    "-   Model contains `genes`, `transcripts` and arbitrary sub-features (e.g., `exons`, `introns`, 3'/5'-`UTR`s, `CDS`) as defined\n",
    "    in the GFF file. Note that `intron` annotations are calculated automatically from exon annotations unless configured otherwise. \n",
    "    Frozen dataclasses (derived from the 'Feature' class) are created for all parsed feature types automatically and users may configure which \n",
    "    GTF/GFF attributes will be parsed and added to those dataclasses as fields.\n",
    "    Gene intervals must envelop transcript intervals which must envelop sub-feature intervals.\n",
    "    \n",
    "-   A transcriptome maintains an `anno` dict that maps (frozen) features to dicts of arbitrary annotation values which supports the (incremental) annotation of annotation features. Annotation values can be accessed like GFF-parsed fields via 'dot' notation: `<feature>.<attribute>`. \n",
    "    \n",
    "-   The implementation exploits the hierarchical relationship between genes and their sub-features to optimize storage and computational requirements where possible.        \n",
    "    Genomic sequences, for example, can be loaded from a reference genome via load_sequence_datas() but will only be directly stored in strings attached to gene feature.\n",
    "    Sequences can then be accessed via transcriptome.get_sequence(). For sub-features (e.g., transcripts, exons, etc.) the respective sequence will be sliced from the \n",
    "    gene sequence on demand.  Note that despite being computed on demand, genomic sequences can still be accessed via `<feature>.sequence` which will call \n",
    "    transcriptome.get_sequence() with default parameters.\n",
    "    \n",
    "-   The get_sequence() method supports several modes:\n",
    "    If `mode='rna'` is passed, the sequence is returned in 5'-3' orientation, i.e., they are reverse-complemented\n",
    "    for minus-strand transcripts. The returned sequence will, however, still use the DNA alphabet (ACTG) to\n",
    "    enable direct alignment/comparison with genomic sequences.\n",
    "    if `mode='spliced'`, the spliced 5'-3' sequence will be returned.\n",
    "    if `mode='translated'`, the spliced 5'-3' CDS sequence will be returned.\n",
    "    \n",
    "-   Genomic range queries via query() are supported by a combination of interval and linear search queries.\n",
    "    A transcriptome object maintains one intervaltree per chromosome built from gene annotations.\n",
    "    Overlap/envelop queries will first be applied to the respective intervaltree and the (typically small\n",
    "    result sets) will then be filtered, e.g., for requested sub-feature types.\n",
    "    \n",
    "-   Transcriptome models can also be built from subsets of GFF/GTF files by filtering contained transcripts with a TranscriptFilter() that can restrict, e.g., included chromosomes, genomic regions, transcript_ids, gene_types or transcripts with certain 'tag' values (as used in gencode).\n",
    "\n",
    "-   A transcriptome object keeps track of the numbers of filtered GFF entries in a `log` Counter object that is, e.g., useful for debugging. The 'structure' of the parsed features can be accessed via the `get_struct()` method.\n",
    "\n",
    "The following cells demonstrate some use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7f7f7-c82d-4d05-8983-caedd5ff681f",
   "metadata": {},
   "source": [
    "![transcriptome datamodel](../docs/_static/rnalib_transcriptome.png \"Transcriptome datamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729131e5-fab9-4cee-930e-40a19019f3d7",
   "metadata": {},
   "source": [
    "### Basic access examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e471e34-334e-4c7f-af37-222d6df3e15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's create a transcriptome containing dmel chromosome 2L annotation from a flybase annotation file.\n",
    "t = pg.Transcriptome(\n",
    "        genome_fa=pg.get_resource('dmel_genome'),      # genome FASTA\n",
    "        annotation_gff=pg.get_resource('flybase_gtf'), # Gene annotation GTF/GFF file\n",
    "        annotation_flavour='flybase',               # flavour of the annotation file.\n",
    "        load_sequence_data=True, # load sequences from configured genome FASTA file\n",
    "        disable_progressbar=True, # no progressbars,\n",
    "        feature_filter={'location': { 'included': { 'chromosomes': ['2L'] } }} # a simple filter that will include only annotations from 2L\n",
    "    ) \n",
    "# show some stats/debugging information\n",
    "display(t) # show some basic info (#genes, #tx)\n",
    "display(t.get_struct()) # Show the hierarchical structure encoded in the GFF\n",
    "display(t.log) # show stats (such as parsed and filtered lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219dabf-fba9-4d25-8176-844d93e2cdb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, we can access some data:                              \n",
    "# show gene names that were parsed from the flybase 'gene_symbol' field\n",
    "display(f\"Gene names: {[g.gene_name for g in t.genes]}\",SEP) \n",
    "# query gene by name and get its transcripts\n",
    "display(f\"Transcripts of gene 'l(2)gl': {[tx.feature_id for tx in t.gene['l(2)gl'].transcript]}.\",SEP) \n",
    "# get number of exons per transcripts\n",
    "display(f\"Number of exons per Cda5 tx: { {tx.feature_id:len(tx.exon) for tx in t.gene['Cda5'].transcript} }\",SEP) \n",
    "# Access transcript by id and show the name field of its gene (=parent)\n",
    "display(f\"The parent gene of transcript 'FBtr0330655' is {t.transcript['FBtr0330655'].parent.gene_name}\",SEP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dade69-ec27-4745-966f-542ead42a887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some more access examples\n",
    "# genes can be accessed by name or gene id; their location\n",
    "display(f\"The gene {t.gene['l(2)gl'].gene_name} is located on chromosome {t.gene['l(2)gl'].location.chromosome} at {t.gene['FBgn0002121'].location} \", SEP) \n",
    "\n",
    "# you can inspect the fields of a transcriptome feature with regular python methods, e.g. vars()\n",
    "# Here we show, e.g., the structure of the 1st transcript\n",
    "tx = t.gene['l(2)gl'].transcript[0]\n",
    "display_textarea(pprint.pformat(vars(tx)))\n",
    "\n",
    "# fields as well as dynamic annotations (see below) can be accessed by <feature>.<attribute/field> notation\n",
    "# this includes calculated annotations such as location and rnk (exon/intron number)\n",
    "display(f\"transcript_id: {tx.feature_id}, location: {tx.location}, 1st exon rnk: {tx.exon[0].rnk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60abc5-91a3-479a-a2d9-3e02d29fd554",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sequence access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda166c-385c-42c8-958a-b9afb116585c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Genomic sequences are another example for dynamically calculated annotations. \n",
    "# They must first be loaded for each gene annotation with load_sequence_datas() \n",
    "# which is done automatically if 'load_sequence_datas': True is configured.\n",
    "# They can be accessed by the t.get_sequence() method or by <feature>.sequence which calls \n",
    "# get_sequence() with default params.\n",
    "# We demonstrate this by accessing some data of a transcript of the 'l(2)gl (FBgn0002121)' gene\n",
    "rand_tx = random.sample(t.gene['l(2)gl'].transcript,1)[0]\n",
    "display(f\"Selected tx: {rand_tx.feature_id}\")\n",
    "display_textarea(f\"DNA sequence of 1st exon: {rand_tx.exon[0].sequence}\")\n",
    "display_textarea(f\"Spliced sequence: {rand_tx.spliced_sequence}\")\n",
    "\n",
    "# SJs can be displayed by calling get_sequence(mode='spliced', show_exon_boundaries=True)\n",
    "display_textarea(f\"Spliced sequence showing SJ ('*'): {t.get_sequence(rand_tx, mode='spliced', show_exon_boundaries=True)}\")\n",
    "\n",
    "# sequences will be reverse complemented for - strand transcripts if mode='rna'\n",
    "# get some random minustrand tx\n",
    "tx=random.sample([tx for tx in t.transcripts if tx.strand=='-'], 1)[0]\n",
    "\n",
    "# show sequence of 1st exon in dna and rna mode (reverse complement as the gene is on the - strand)\n",
    "display(f\"tx {tx.feature_id}, exon 1: dnaseq={t.get_sequence(tx.exon[0], mode='dna')}, rnaseq={t.get_sequence(tx.exon[0], mode='rna')}\", SEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd281e-d879-4ce3-a277-c540b8ac001b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The transcriptome implementation also supports (annotated) CDS annotations. Users can directly access the translated sequence:\n",
    "display_textarea(f\"Translated sequence of FBtr0330655: {t.transcript['FBtr0330655'].translated_sequence}\")\n",
    "\n",
    "# align spliced (including 5'/3' UTRs) and translated sequence using biopython\n",
    "display_textarea(next(PairwiseAligner(mode='global', open_gap_score=-3).align(\n",
    "        t.transcript['FBtr0330655'].translated_sequence, \n",
    "        t.transcript['FBtr0330655'].spliced_sequence)))\n",
    "    \n",
    "# translate with biotite\n",
    "display_textarea(f\"Amino acid sequence of FBtr0078164: {seq.NucleotideSequence(t.transcript['FBtr0330655'].translated_sequence).translate(complete=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d9d92-3f63-48ad-bbf6-100c3a67aeff",
   "metadata": {},
   "source": [
    "Exact kmer search in sequences can be performed by standard python methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0fc8a-5ec9-4000-a0e2-1a419f90d383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all gene names where the kmer is found in one of the (spliced) transcripts\n",
    "display(f\"Genes containing ATGC kmer in one of their (spliced) tx: { { tx.parent.gene_name for tx in t.transcripts if 'ATGC' in tx.spliced_sequence }}\", SEP)\n",
    "\n",
    "# list all gene names where the kmer is found in one of its transcripts introns considering only long (>1kb) introns\n",
    "display(f\"Genes containing ATGC kmer in a long (>1kb) intron: { { tx.parent.gene_name for tx in t.transcripts for intron in tx.intron if len(intron)>1000 and 'ATGC' in intron.sequence}}\", SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5716575-f662-454e-a9c4-75c279115bb8",
   "metadata": {},
   "source": [
    "### Querying\n",
    "Transcriptome features can be effieciently queried via python list comprehension or \n",
    "via interval-tree based range queries.\n",
    "    \n",
    "In the following example, we demonstrate both approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db73c29-b1dd-4ade-ae8f-1e058e6a3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all minus strand genes with transcripts that have >=2 exons and at least one long (>1kb) intron via list comprehension\n",
    "{tx.parent.gene_name for tx in t.transcripts if tx.strand=='-' and len(tx.exon)>=2 and any([len(i)>1000 for i in tx.intron])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf0328-d9d9-4f70-afb7-fee14a426268",
   "metadata": {},
   "source": [
    "#### Range queries\n",
    "\n",
    "Efficient range queries are implemented by prefiltering the data using per-chromosome [intervaltrees](https://github.com/chaimleib/intervaltree). The respective interval trees are built automatically by\n",
    "the transcriptome class and can be queried via the `query()` method which is demonstrated below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaab7f1-1481-4f5c-8ccc-02a923afc530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Efficient range queries are implemented by intervaltrees:\n",
    "display(f\"Genes where an exon overlaps with 2L:10000-20000: { {ex.parent.parent.gene_name for ex in t.query(gi.from_str('2L:10000-20000'), 'exon')}}\", SEP) \n",
    "\n",
    "# Query all transcripts that overlap with the 'l(2)gl' gene and create a set with their gene names.\n",
    "l2gl=t.gene['l(2)gl'] # note that each transcriptome feature is also a genomic interval and can be queried\n",
    "display(f\"Genes of all transcripts that overlap with gene 'l(2)gl': {set(tx.parent.gene_name for tx in t.query(l2gl, 'transcript'))}\", SEP) \n",
    "\n",
    "# report a coordinate-sorted list of genes in a 10kb window around cold:\n",
    "display(f\"Genes near 'l(2)gl': { [g.gene_name for g in t.query(gi(l2gl.chromosome, l2gl.start-3000, l2gl.end+3000), 'gene')]}\", SEP)\n",
    "\n",
    "# envelop queries are also supported:\n",
    "display(f\"Genes contained in a +/- 10kb window around 'l(2)gl': { [g.gene_name for g in t.query(gi(l2gl.chromosome, l2gl.start-3000, l2gl.end+3000), 'gene', envelop=True)]}\", SEP)\n",
    "\n",
    "# Direct access to the interval trees is possible via the chr2itree attribute. Here, we query intervals\n",
    "# at position 2L:20000. The respective gene object can be accessed via the data slot.\n",
    "display(f\"Genes at 2L:20000: {[x.data.feature_id for x in t.chr2itree['2L'].at(20000)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b314ed9-1dc4-499b-a645-1125f7c86a76",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Accessing up/downstream genes\n",
    "The gene_triples() method yields genes and their neighbouring (up-/downstream) within a given maximum distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a08ef-b739-4f22-9fb1-e10c7d082ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate genes and their up/downstream genes within a given max distance. Show only first 10 entries.\n",
    "def get_name(x):\n",
    "    return None if x is None else x.gene_name\n",
    "display([(get_name(x),get_name(y),get_name(z)) for x, y, z in t.gene_triples(max_dist=10000)][:10])\n",
    "\n",
    "# Note that the distance between lncRNA:CR46254 and lncRNA:CR45339 is > 10kb\n",
    "display(f\"Distance between lncRNA:CR46254 and lncRNA:CR45339: {t.gene['lncRNA:CR46254'].distance(t.gene['lncRNA:CR45339'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2dbe4-458f-47dd-9edf-fe30ae35cccf",
   "metadata": {},
   "source": [
    "#### Accessing 3'-ends\n",
    "The calc_3end() method returns a list of genomic interval(s) containing the last <width> bases\n",
    "of a passed transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9597159-9842-4e1f-a53f-768fe329443a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dict of genes and their unique 1000bp 3'UTR intervals per tx (multiple intervals if spliced); \n",
    "# note that for, e.g., Ir21a/FBtr0113008 2 intervals are reported as the 1000bp UTR overlaps a splice junction\n",
    "display({g.gene_name: {tx.feature_id:pg.calc_3end(tx, width=1000) for tx in g.transcript} for g in t.genes})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116befa-db0d-4d9d-8a73-3245cb3e1dae",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Accessing up-/downstream windows\n",
    "Here we iterate all transcripts and calculate a downstream (3') genomic window and its dna sequence. \n",
    "For demonstration purposes, we show only the first three 3'-end bases.\n",
    "(NOTE: For adding 5'-end windows, just use 'upstream' as window_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935c39b-d1e7-4c85-a708-e1ea00850df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_type='downstream'\n",
    "ws=3\n",
    "# NOTE that if you use a sliced genome sequence, you have to correct coordinates using the respective 'genome_offsets' \n",
    "# values. We have added the respective code here although this example works with a full dmel genome sequence.\n",
    "with pysam.Fastafile(t.genome_fa) as fasta:\n",
    "    for tx in tqdm(t.transcripts, desc=f'Load {window_type} window sequences', total=len(t.transcripts)):\n",
    "        strand = tx.strand\n",
    "        assert strand is not None, f\"Undefined strand for tx {tx}\"\n",
    "        loc = tx.get_upstream(ws) if window_type == 'upstream' else tx.get_downstream(ws)  # get up/downstream windows of given size\n",
    "        dna_seq=''\n",
    "        s = loc.start - t.genome_offsets.get(loc.chromosome, 1) \n",
    "        if s<0: # Pad with N's if required\n",
    "            dna_seq='N'*(-s)\n",
    "            s=0\n",
    "        e = loc.end - t.genome_offsets.get(loc.chromosome, 1) + 1\n",
    "        dna_seq+=fasta.fetch(reference=loc.chromosome,start=s,end=e) # get sequence from FASTA\n",
    "        display(f\"{window_type}: {tx.parent.gene_name},{tx.feature_id}, {loc}, {dna_seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb681a0c-342c-46c1-9487-e441ac8cfc67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Annotation\n",
    "\n",
    "A transcriptome manages an `anno` dict that maps annotation features (e.g., an exon) to a dict containing arbitray annotations.\n",
    "Annotations can be added manually or by using the `transcriptome.annotate()` method that implements a generic method to add feature-based annotations based on rnalib's [`AnnotationIterator`](#AnnotationIterator). The following section demonstrates some use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a911370-0c34-48b3-bce6-c3e3114568eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's instantiate a small transcriptome that contains only two human genes (ACTB and SOX2) \n",
    "t=pg.Transcriptome(\n",
    "    genome_fa=pg.get_resource('ACTB+SOX2_genome'),  # reference genome FASTA\n",
    "    genome_offsets= {'chr3': 181711825, 'chr7': 5526309}, # This is a sliced reference sequence. To match the gencode annotations we provide respective offset coordinates for the 2 chroms\n",
    "    annotation_gff=pg.get_resource('gencode_gff'),  # gene annotation GFF\n",
    "    annotation_flavour='gencode', # this is a gencode flavoured GFF\n",
    "    load_sequence_data=True # load gene sequences from reference genome)\n",
    ")\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf1626-a0f3-4987-9aa3-1bef5b7ab57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, lets annotate exons and introns with mappability scores that are read from a bedgraph file.\n",
    "# We first create a method for calculating the mean mappability for an annotation based on the scores of\n",
    "# all overlapping intervals from the bedgraph file.\n",
    "def calc_mean(item, label='mappability'):\n",
    "    loc, (anno, scores) = item\n",
    "    anno[label]=sum([score*loc.overlap(sloc) for sloc,score in scores])/len(loc)\n",
    "    return calc_mean\n",
    "\n",
    "# now we can call the annotate method, tell it to get the scores from a bedgraph iterator and\n",
    "# to annotate only exons + introns. Note that this test bedgraph file covers only ~half of ACTB,\n",
    "# (use a genome  browser like IGV to confirm this). So the mappability of the uncovered regions will \n",
    "# be set to zero.\n",
    "t.annotate(iterators=pg.BedGraphIterator(pg.get_resource('human_umap_k24')),\n",
    "           fun_anno=calc_mean,\n",
    "           feature_types=['exon', 'intron'])\n",
    "\n",
    "# Now, lets show the mappability values for exons and introns of one random transcript \n",
    "rnd_tx = random.sample(t.gene['ACTB'].transcript, 1)[0]\n",
    "display(SEP, \"Mappability for a random ACTB transcript:\", [(f.rnk, f.feature_id, f.mappability) for f in rnd_tx.exon])\n",
    "# Note that it would be more efficient to annotate genes with mappability score arrays and then calculate mean/median mappability\n",
    "# for each feature by slicing these arrays (as done, e.g., for sequences) but this is omitted here for the sake of simplicity\n",
    "\n",
    "\n",
    "# use get/getattr to provide sensible default values for missing data:\n",
    "display(SEP, \"Some annotated values:\")\n",
    "display(f\"exon mappability value: {t.transcript['ENST00000477812.2'].exon[0].get('mappability',None)}\") # show some mappability value\n",
    "display(f\"gene mappability value: {t.gene['ACTB'].get('mappability',None)}\") # only exons/introns were annotated above\n",
    "display_textarea(f\"exon sequence: {t.transcript['ENST00000477812.2'].exon[0].get('sequence',None)}\") # here, the sequence is sliced from the parent gene\n",
    "\n",
    "# We can also convert results to a dataframe (but note that we lose the parent/child relationships here).\n",
    "df = pg.TranscriptomeIterator(t).to_dataframe()\n",
    "# let's use the pandas query method to show features from protein_coding genes with non-zero mappability...\n",
    "display(SEP, \"Dataframe representation\", df.query('gene_type==\"protein_coding\" & mappability>0'),SEP)\n",
    "# ...and plot the overall mappability distribution...\n",
    "df['mappability'].plot(kind='hist', title='mappability histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159fe67-cc93-428b-acb2-a47a47cac59f",
   "metadata": {},
   "source": [
    "#### Example: Calculate number of overlapping features\n",
    "In this example, we calculate the number of overlapping introns per exon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d594c-4c4a-4f02-a8b3-db6cbd1a67c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we calculate the number of overlapping introns per exon.\n",
    "def count_anno(item):\n",
    "    loc, (anno, overlapping) = item\n",
    "    # Here we simply count the number of overlapping intron annotations but we could also group\n",
    "    # by tx or gene, etc.\n",
    "    anno['n_overlapping_introns']=len(overlapping)\n",
    "    anno['overlapping_introns']=overlapping\n",
    "\n",
    "# now we can call the annotate method for all exons of this transcriptome and tell it to \n",
    "# annotate with all introns of this transcriptome. In the passed annotation method (count_anno) we \n",
    "# simply count the number of overlapping annotations (introns).\n",
    "# Its easy to check in IGV (loading the GFF3 file) whether the numbers are correct.\n",
    "t.clear_annotations() # make sure to remove previously added annotations\n",
    "t.annotate(iterators=pg.TranscriptomeIterator(t,feature_types=['intron']),\n",
    "           fun_anno=count_anno,\n",
    "           feature_types=['exon'])\n",
    "\n",
    "# Here we create a histogram ...\n",
    "intron_hist=Counter()\n",
    "for ex in pg.TranscriptomeIterator(t,feature_types=['exon']):\n",
    "    intron_hist[ex.data['n_overlapping_introns']]+=1\n",
    "\n",
    "# ... and plot it\n",
    "x, y = zip(*intron_hist.items())\n",
    "_=plt.bar(x,y)\n",
    "plt.xlabel(\"# overlapping introns\")\n",
    "plt.ylabel(\"n\")\n",
    "_=plt.suptitle(\"Number of overlapping intron annotations\")\n",
    "\n",
    "# Here we show one example with max number of overlapping introns\n",
    "# NOTE that there can be multiple introns per transcript that overlap with a given exon.\n",
    "for ex,info in pg.TranscriptomeIterator(t,feature_types=['exon']):\n",
    "    if info.get('n_overlapping_introns', 0)==max(intron_hist):\n",
    "        tids = {i.parent.feature_id for i,_ in info['overlapping_introns']}\n",
    "        display(f\"Example {ex} with {info['n_overlapping_introns']} overlapping introns: { {i.feature_id for i,_ in info['overlapping_introns']} }, tids: {tids}\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd903e5-474b-420e-8a38-031e835d1add",
   "metadata": {},
   "source": [
    "### Conversion to a dataframe\n",
    "Finally, we want to convert the data to a pandas dataframe containing all exons and include two custom colums, one containig the feature length and the other the gene name.\n",
    "\n",
    "The to_dataframe() method supports the flexible construction of such dataframes (e.g., for further processing via bioframe, etc.) as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f438d79-6285-4565-aaae-3c6b72822f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe with a custom conversion function\n",
    "# Here we iterate only exons and custom data columns to the created dataframe:\n",
    "# * it retrieves the 'gene_name' via the transcriptome model.\n",
    "# * it calculates a 'feature length' from the exon interval\n",
    "# * it converts the annotated 'overlapping_introns' list to a comma-separated string\n",
    "# Finally, we add the new columns to the dataframe and drop some we do not need.\n",
    "def my_fun(loc, item, fun_col, default_value): \n",
    "    return [loc.parent.parent.gene_name if col=='gene_name' else # get the gene_name from the grand-parent (=gene) feature \\\n",
    "            len(loc) if col=='feature_len' else # calc fature length \\\n",
    "            ','.join([str(x.location.feature_id) for x in loc.get(col, default_value)]) if col=='overlapping_introns' else # convert list of items to comma-separated string \\\n",
    "            loc.get(col, default_value) # get annotation from the feature directly \\\n",
    "            for col in fun_col]\n",
    "\n",
    "df = t.iterator(feature_types='exon').to_dataframe( \\\n",
    "         fun=my_fun, # passes our annotation function\n",
    "         included_columns=('feature_len',), # include our new column\n",
    "         excluded_columns=('dna_seq', 'source', 'gff_feature_type') # columns that are dropped\n",
    "        )\n",
    "\n",
    "df.head(3)  # report max 3 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44a6fb-0556-4cac-8bb2-a1f8f0ee8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also 'describe' a dataset which converts it to a pandas dataframe and calls describe\n",
    "# Additionally it calculates some stats such as whether this dataset contains overlapping or empty intervals.\n",
    "df, stats = pg.TranscriptomeIterator(t, feature_types='exon').describe(fun=my_fun)\n",
    "display(df.head(5))\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398f9e4-099c-4761-8642-08b0dc403d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, for example, we iterate over the 1st 100 reads of a BAM file and get some summary statistics for the\n",
    "# NM (number of mismatches) and NH (number of hits) tags\n",
    "df, stats = pg.ReadIterator(pg.get_resource('small_example_bam')).describe(\\\n",
    "         fun=lambda loc, item, fun_col, default_value:[item.get_tag(col) for col in fun_col] , \\\n",
    "         fun_col=('NM', 'NH'), # include our new column\n",
    "         max_items=100) # report max 100 items\n",
    "display(df.head(5))\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c2772-c2ad-454c-831d-9ca289a5ca46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utility functions\n",
    "\n",
    "_rnalib_ also contains a number of utility functions which might be useful for handling genomics data. Some of those functions were demonstrated already in the context of this notebook. Here we present and document them in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac210d22-cc7d-4855-8402-cfb35bb2b614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gene symbols are updated regularly and mapping between different id schemas is cumbersome\n",
    "# rnalib implements an interface to MyGeneInfo for easy translation between ids and symbols \n",
    "# Example: we pass a mixed list of Ensembl and Entrez ids for mouse and human  actin beta:\n",
    "pg.geneid2symbol(['ENSMUSG00000029580', 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b83a6e-7f5d-430b-8c58-904612b75b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another possibility is to use alias files that provide a mapping from previous (outdated) to current gene symbols.\n",
    "# rnalib supports such alias files and here we showcase this by loading a small subset of genenames.org data \n",
    "# and using it to convert lists containing partially old gene symbols to their current symbol.\n",
    "aliases, current_symbols = pg.read_alias_file(pg.get_resource('hgnc_gene_aliases'))\n",
    "# now lets translate some gene symbols\n",
    "display(pg.norm_gn('A2MP', current_symbols, aliases), \n",
    "        pg.norm_gn('FLJ23569', current_symbols, aliases),\n",
    "        pg.norm_gn('A2MP1', current_symbols, aliases)) \n",
    "# Please note that the transcriptome implementation has implicit support for gene name aliasing, all you need to do is to pass a file path refering to a\n",
    "# genenames.org like file via the 'gene_name_alias_file' config property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e064903-9412-44a2-8590-1ed5785a7b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# And utilities to work with Nanopore data (FAST5 files)\n",
    "# You can, e.g., inspect the structure of such a file:\n",
    "fast5_file=pg.get_resource('nanoseq_fast5_raw')\n",
    "pg.print_fast5_tree(fast5_file, show_attrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96d57e-061f-4264-856d-e1bc5f0d3a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Or list the basecalling groups in this file\n",
    "fast5_file=pg.get_resource('nanoseq_fast5_basecalled')#'testdata/fast5/FAT61995_a1291c8f_5.fast5'\n",
    "pg.get_bcgs(fast5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d947d-1612-4706-a9ba-61d89cd90580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the get_covered_contigs() method accesses a BAM index and quickly calculates which\n",
    "# contigs contain reads:\n",
    "pg.get_covered_contigs(pg.get_resource('small_example_bam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89886344-7074-472a-a2ab-a2bafbdf634a",
   "metadata": {},
   "source": [
    "Please refer to the test_utils.py script for usage scenarios of other rnalib utility methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
